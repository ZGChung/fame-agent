#!/usr/bin/env python3
"""
è§†é¢‘ç”Ÿæˆæ¨¡å—
æ”¯æŒå¤šç§ AI è§†é¢‘ç”ŸæˆæœåŠ¡

ä½¿ç”¨æ–¹å¼:
1. é…ç½®è§†é¢‘ç”ŸæˆæœåŠ¡ API
2. è°ƒç”¨ generate_video() ç”Ÿæˆè§†é¢‘
3. é›†æˆåˆ° pipeline

æ”¯æŒçš„è§†é¢‘ç”Ÿæˆæ–¹å¼:
- Runway ML (text to video, image to video)
- Pika Labs (text to video, image to video)
- Luma Dream Machine (image to video)
- æœ¬åœ° ffmpeg (å›¾ç‰‡ç”Ÿæˆè§†é¢‘)
"""

import os
import json
import asyncio
import subprocess
from pathlib import Path
from typing import Optional, List
from datetime import datetime

# é…ç½®
CONFIG_FILE = Path(__file__).parent.parent / "config.json"

def load_config() -> dict:
    """åŠ è½½é…ç½®"""
    if CONFIG_FILE.exists():
        with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}


class VideoGenerator:
    """è§†é¢‘ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.config = load_config()
        self.video_config = self.config.get('video', {})
    
    def is_configured(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦é…ç½®äº†ä»»æ„è§†é¢‘æœåŠ¡"""
        return bool(
            self.video_config.get('runway_api_key') or
            self.video_config.get('pika_api_key') or
            self.video_config.get('luma_api_key') or
            self.video_config.get('heygen_api_key')
        )
    
    async def generate_from_images(
        self,
        images: List[str],
        output_path: str = None,
        duration_per_image: float = 3.0,
        transition: str = "fade"
    ) -> str:
        """
        ä»å›¾ç‰‡ç”Ÿæˆè§†é¢‘ï¼ˆå¹»ç¯ç‰‡ï¼‰
        
        Args:
            images: å›¾ç‰‡è·¯å¾„åˆ—è¡¨
            output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
            duration_per_image: æ¯å¼ å›¾ç‰‡æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
            transition: è½¬åœºæ•ˆæœ (fade, slide, none)
        
        Returns:
            str: ç”Ÿæˆè§†é¢‘çš„è·¯å¾„
        """
        if not images:
            raise ValueError("éœ€è¦æä¾›è‡³å°‘ä¸€å¼ å›¾ç‰‡")
        
        if not output_path:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = f"output/{timestamp}_video.mp4"
        
        # ä½¿ç”¨ ffmpeg ç”Ÿæˆè§†é¢‘
        success = await self._ffmpeg_slideshow(
            images, output_path, duration_per_image, transition
        )
        
        if success:
            return output_path
        raise RuntimeError("è§†é¢‘ç”Ÿæˆå¤±è´¥")
    
    async def _ffmpeg_slideshow(
        self,
        images: List[str],
        output_path: str,
        duration: float,
        transition: str
    ) -> bool:
        """ä½¿ç”¨ ffmpeg ç”Ÿæˆå¹»ç¯ç‰‡è§†é¢‘"""
        
        output_dir = Path(output_path).parent
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # å¦‚æœåªæœ‰ä¸€å¼ å›¾ç‰‡ï¼Œä½¿ç”¨ Ken Burns æ•ˆæœ
        if len(images) == 1:
            # Ken Burns: slow zoom in
            cmd = [
                'ffmpeg', '-y',
                '-loop', '1',
                '-i', images[0],
                '-c:v', 'libx264',
                '-t', str(duration),
                '-pix_fmt', 'yuv420p',
                '-vf', f'scale=1080:1920:force_original_aspect_ratio=decrease,pad=1080:1920:(ow-iw)/2:(oh-ih)/2,zoompan=z=\'min(zoom+0.001,1.5)\':d={int(duration*25)}:s=1080x1920',
                output_path
            ]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
            return result.returncode == 0
        
        # å¤šå¼ å›¾ç‰‡ï¼šåˆ›å»ºç‰‡æ®µååˆå¹¶
        try:
            temp_videos = []
            # ä½¿ç”¨ç»å¯¹è·¯å¾„ç¡®ä¿æ­£ç¡®
            output_dir = Path(output_path).resolve().parent
            output_dir.mkdir(parents=True, exist_ok=True)
            
            for i, img in enumerate(images):
                img_path = Path(img).resolve()
                temp_out = output_dir / f"temp_{i}.mp4"
                cmd = [
                    'ffmpeg', '-y',
                    '-loop', '1',
                    '-i', str(img_path),
                    '-c:v', 'libx264',
                    '-t', str(duration),
                    '-pix_fmt', 'yuv420p',
                    '-vf', f'scale=1080:1920:force_original_aspect_ratio=decrease,pad=1080:1920:(ow-iw)/2:(oh-ih)/2',
                    '-r', '30',
                    str(temp_out)
                ]
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
                if result.returncode != 0:
                    print(f"åˆ›å»ºç‰‡æ®µå¤±è´¥: {result.stderr[:200]}")
                    return False
                temp_videos.append(str(temp_out))
            
            # åˆå¹¶ - ä½¿ç”¨ concat demuxer æ–¹å¼
            concat_file = output_dir / "concat.txt"
            with open(concat_file, 'w') as f:
                for v in temp_videos:
                    f.write(f"file '{v}'\n")
            
            cmd = [
                'ffmpeg', '-y',
                '-f', 'concat',
                '-safe', '0',
                '-i', str(concat_file),
                '-c:v', 'libx264',
                '-preset', 'fast',
                '-crf', '23',
                '-c:a', 'aac',
                '-b:a', '128k',
                output_path
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)
            
            # æ¸…ç†
            for v in temp_videos:
                Path(v).unlink()
            concat_file.unlink()
            
            return result.returncode == 0
            
        except Exception as e:
            print(f"FFmpeg ç”Ÿæˆå¤±è´¥: {e}")
            return False
    
    async def generate_text_to_video(
        self,
        prompt: str,
        service: str = "runway",
        output_path: str = None
    ) -> str:
        """
        æ–‡å­—ç”Ÿæˆè§†é¢‘
        
        Args:
            prompt: è§†é¢‘æè¿°
            service: æœåŠ¡å•† (runway, pika, luma, seedance)
            output_path: è¾“å‡ºè·¯å¾„
        
        Returns:
            str: è§†é¢‘è·¯å¾„
        """
        if service == "runway":
            return await self._runway_generate(prompt, output_path)
        elif service == "pika":
            return await self._pika_generate(prompt, output_path)
        elif service == "luma":
            return await self._luma_generate(prompt, output_path)
        elif service == "seedance":
            return await self._seedance_generate(prompt, output_path)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æœåŠ¡: {service}")
    
    async def _runway_generate(self, prompt: str, output_path: str) -> str:
        """Runway ML API"""
        api_key = self.video_config.get('runway_api_key')
        if not api_key:
            raise ValueError("éœ€è¦é…ç½® Runway API Key")
        
        # TODO: å®ç° Runway API è°ƒç”¨
        # API: https://api.runwayml.com/v1/generation
        raise NotImplementedError("Runway API é›†æˆå¼€å‘ä¸­")
    
    async def _pika_generate(self, prompt: str, output_path: str) -> str:
        """Pika Labs API"""
        api_key = self.video_config.get('pika_api_key')
        if not api_key:
            raise ValueError("éœ€è¦é…ç½® Pika API Key")
        
        # TODO: å®ç° Pika API è°ƒç”¨
        raise NotImplementedError("Pika API é›†æˆå¼€å‘ä¸­")
    
    async def _luma_generate(self, prompt: str, output_path: str) -> str:
        """Luma Dream Machine API"""
        api_key = self.video_config.get('luma_api_key')
        if not api_key:
            raise ValueError("éœ€è¦é…ç½® Luma API Key")
        
        # TODO: å®ç° Luma API è°ƒç”¨
        raise NotImplementedError("Luma API é›†æˆå¼€å‘ä¸­")
    
    async def _seedance_generate(self, prompt: str, output_path: str) -> str:
        """
        Seedance 2.0 API
        
        æ³¨æ„: Seedance 2.0 å¯èƒ½å°šæœªå…¬å¼€å‘å¸ƒï¼Œç­‰å¾…å®˜æ–¹ API
        """
        api_key = self.video_config.get('seedance_api_key')
        if not api_key:
            # å¦‚æœæ²¡æœ‰ API Keyï¼Œä½¿ç”¨æœ¬åœ°ç”Ÿæˆä½œä¸ºå¤‡é€‰
            print("âš ï¸ Seedance API Key æœªé…ç½®ï¼Œä½¿ç”¨æœ¬åœ°è§†é¢‘ç”Ÿæˆ")
            # è¿”å›ç©ºå­—ç¬¦ä¸²è®©è°ƒç”¨æ–¹ä½¿ç”¨æœ¬åœ°ç”Ÿæˆ
            return ""
        
        # TODO: Seedance 2.0 API é›†æˆ
        # ç­‰å¾…å®˜æ–¹å‘å¸ƒåå®ç°
        raise NotImplementedError("Seedance 2.0 API é›†æˆå¼€å‘ä¸­ - ç­‰å¾…å®˜æ–¹å‘å¸ƒ")
    
    async def add_subtitles(
        self,
        video_path: str,
        subtitles: List[dict],
        output_path: str = None
    ) -> str:
        """
        ä¸ºè§†é¢‘æ·»åŠ å­—å¹•
        
        æ³¨æ„: éœ€è¦ ffmpeg ç¼–è¯‘æ—¶åŒ…å« --enable-libass æ‰èƒ½ä½¿ç”¨
        å½“å‰ç‰ˆæœ¬ä¸æ”¯æŒï¼Œä¿ç•™æ¥å£ä¾›å°†æ¥ä½¿ç”¨
        
        Args:
            video_path: è§†é¢‘è·¯å¾„
            subtitles: å­—å¹•åˆ—è¡¨ [{"text": "æ–‡å­—", "start": 0, "end": 3}]
            output_path: è¾“å‡ºè·¯å¾„
        
        Returns:
            str: å¸¦å­—å¹•çš„è§†é¢‘è·¯å¾„
        """
        # TODO: éœ€è¦é‡æ–°ç¼–è¯‘ ffmpeg --enable-libass æ‰èƒ½ä½¿ç”¨å­—å¹•åŠŸèƒ½
        # å½“å‰ç‰ˆæœ¬ä¸æ”¯æŒ subtitles æ»¤é•œ
        raise NotImplementedError(
            "å­—å¹•åŠŸèƒ½éœ€è¦ ffmpeg åŒ…å« libass æ”¯æŒã€‚"
            "è¯·ä½¿ç”¨ Homebrew é‡æ–°å®‰è£…: brew reinstall ffmpeg --with-libass"
        )
    
    def _format_srt_time(self, seconds: float) -> str:
        """æ ¼å¼åŒ– SRT æ—¶é—´"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millis = int((seconds % 1) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"
    
    async def add_background_music(
        self,
        video_path: str,
        music_path: str,
        output_path: str = None,
        music_volume: float = 0.3
    ) -> str:
        """
        æ·»åŠ èƒŒæ™¯éŸ³ä¹
        
        Args:
            video_path: è§†é¢‘è·¯å¾„
            music_path: éŸ³ä¹æ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºè·¯å¾„
            music_volume: éŸ³ä¹éŸ³é‡ (0.0-1.0)
        
        Returns:
            str: å¸¦èƒŒæ™¯éŸ³ä¹çš„è§†é¢‘è·¯å¾„
        """
        if not output_path:
            output_path = video_path.replace('.mp4', '_with_music.mp4')
        
        cmd = [
            'ffmpeg', '-y',
            '-i', video_path,
            '-i', music_path,
            '-filter_complex',
            f'[1:a]volume={music_volume}[music];[0:a][music]amix=inputs=2:duration=first[aout]',
            '-map', '0:v',
            '-map', '[aout]',
            '-c:v', 'copy',
            '-shortest',
            output_path
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)
        
        if result.returncode == 0:
            return output_path
        raise RuntimeError(f"èƒŒæ™¯éŸ³ä¹æ·»åŠ å¤±è´¥: {result.stderr[:200]}")
    
    async def create_ken_burns_video(
        self,
        image_path: str,
        output_path: str = None,
        duration: float = 5.0,
        zoom_direction: str = "in"
    ) -> str:
        """
        åˆ›å»º Ken Burns æ•ˆæœè§†é¢‘ï¼ˆè‡ªåŠ¨ç¼©æ”¾ï¼‰
        
        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            output_path: è¾“å‡ºè·¯å¾„
            duration: è§†é¢‘æ—¶é•¿
            zoom_direction: ç¼©æ”¾æ–¹å‘ ("in", "out", "pan")
        
        Returns:
            str: ç”Ÿæˆçš„è§†é¢‘è·¯å¾„
        """
        if not output_path:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = f"output/{timestamp}_kenburns.mp4"
        
        output_dir = Path(output_path).parent
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # æ ¹æ®ç¼©æ”¾æ–¹å‘è®¾ç½® zoom å€¼
        if zoom_direction == "in":
            zoom_expr = "min(zoom+0.001,1.5)"
        elif zoom_direction == "out":
            zoom_expr = "max(zoom-0.001,0.5)"
        else:  # pan
            zoom_expr = "1.0+0.1*sin(t)"
        
        cmd = [
            'ffmpeg', '-y',
            '-loop', '1',
            '-i', image_path,
            '-c:v', 'libx264',
            '-t', str(duration),
            '-pix_fmt', 'yuv420p',
            '-vf', f'scale=1080:1920:force_original_aspect_ratio=decrease,pad=1080:1920:(ow-iw)/2:(oh-ih)/2,zoompan=z=\'{zoom_expr}\':d={int(duration*25)}:s=1080x1920',
            '-r', '30',
            output_path
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
        
        if result.returncode == 0:
            return output_path
        raise RuntimeError(f"Ken Burns è§†é¢‘ç”Ÿæˆå¤±è´¥: {result.stderr}")
    
    async def add_audio(
        self,
        video_path: str,
        audio_path: str = None,
        tts_text: str = None,
        output_path: str = None
    ) -> str:
        """
        ä¸ºè§†é¢‘æ·»åŠ éŸ³é¢‘
        
        Args:
            video_path: è§†é¢‘è·¯å¾„
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„ (å¯é€‰)
            tts_text: è¦è½¬è¯­éŸ³çš„æ–‡å­— (å¯é€‰)
            output_path: è¾“å‡ºè·¯å¾„
        
        Returns:
            str: å¸¦éŸ³é¢‘çš„è§†é¢‘è·¯å¾„
        """
        if not output_path:
            output_path = video_path.replace('.mp4', '_with_audio.mp4')
        
        # å¦‚æœæä¾›äº† ttsï¼Œä½¿ç”¨ TTS ç”ŸæˆéŸ³é¢‘
        if tts_text and not audio_path:
            audio_path = await self._generate_tts(tts_text)
            if not audio_path:
                raise ValueError("TTS ç”Ÿæˆå¤±è´¥")
        
        if not audio_path:
            raise ValueError("éœ€è¦æä¾›éŸ³é¢‘æ–‡ä»¶æˆ– TTS æ–‡å­—")
        
        # åˆå¹¶è§†é¢‘å’ŒéŸ³é¢‘
        cmd = [
            'ffmpeg', '-y',
            '-i', video_path,
            '-i', audio_path,
            '-c:v', 'copy',
            '-c:a', 'aac',
            '-shortest',
            output_path
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode == 0:
            return output_path
        raise RuntimeError(f"éŸ³é¢‘åˆå¹¶å¤±è´¥: {result.stderr}")
    
    async def _generate_tts(self, text: str, output_path: str = None, voice: str = None) -> str:
        """ç”Ÿæˆ TTS éŸ³é¢‘
        
        ä¼˜å…ˆä½¿ç”¨ ElevenLabsï¼ˆå¦‚æœé…ç½®ï¼‰ï¼Œå¦åˆ™ä½¿ç”¨ macOS say å‘½ä»¤
        
        Args:
            text: è¦è½¬æ¢çš„æ–‡å­—
            output_path: è¾“å‡ºè·¯å¾„
            voice: è¯­éŸ³åç§° (é»˜è®¤è‡ªåŠ¨é€‰æ‹©ä¸­/è‹±æ–‡)
        """
        # ä¼˜å…ˆä½¿ç”¨ ElevenLabs
        tts_config = self.video_config.get('tts', {})
        elevenlabs_key = tts_config.get('api_key') or os.getenv('ELEVENLABS_API_KEY')
        
        if elevenlabs_key:
            return await self._generate_elevenlabs(text, output_path, voice, elevenlabs_key)
        
        # å›é€€åˆ° macOS say å‘½ä»¤
        return await self._generate_tts_say(text, output_path, voice)
    
    async def _generate_elevenlabs(
        self, 
        text: str, 
        output_path: str = None, 
        voice: str = None,
        api_key: str = None
    ) -> str:
        """ä½¿ç”¨ ElevenLabs ç”Ÿæˆ TTS"""
        import urllib.request
        import urllib.parse
        
        tts_config = self.video_config.get('tts', {})
        voice_id = voice or tts_config.get('voice_id', 'rachel')
        
        if not output_path:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = f"output/{timestamp}_tts.mp3"
        
        output_dir = Path(output_path).parent
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # ElevenLabs API
        url = f"https://api.elevenlabs.io/v1/text_to_speech/{voice_id}"
        
        headers = {
            'Accept': 'audio/mpeg',
            'Content-Type': 'application/json',
            'xi-api-key': api_key
        }
        
        data = json.dumps({
            'text': text,
            'model_id': 'eleven_monolingual_v1',
            'voice_settings': {
                'stability': 0.5,
                'similarity_boost': 0.75
            }
        }).encode('utf-8')
        
        req = urllib.request.Request(url, data=data, headers=headers, method='POST')
        
        try:
            with urllib.request.urlopen(req, timeout=30) as response:
                with open(output_path, 'wb') as f:
                    f.write(response.read())
            return output_path
        except Exception as e:
            raise RuntimeError(f"ElevenLabs TTS å¤±è´¥: {e}")
    
    async def _generate_tts_say(self, text: str, output_path: str = None, voice: str = None) -> str:
        """ä½¿ç”¨ macOS say å‘½ä»¤ç”Ÿæˆ TTS
        
        Args:
            text: è¦è½¬æ¢çš„æ–‡å­—
            output_path: è¾“å‡ºè·¯å¾„
            voice: è¯­éŸ³åç§° (é»˜è®¤è‡ªåŠ¨é€‰æ‹©ä¸­/è‹±æ–‡)
        """
        # è‡ªåŠ¨é€‰æ‹©è¯­éŸ³
        if not voice:
            # ç®€å•çš„ä¸­è‹±æ–‡æ£€æµ‹
            if any('\u4e00' <= c <= '\u9fff' for c in text):
                voice = "Tingting"  # ä¸­æ–‡å¥³å£°
            else:
                voice = "Daniel"  # è‹±æ–‡å­—éŸ³
        
        # å…ˆç”Ÿæˆ aiff
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        aiff_path = f"output/{timestamp}_tts.aiff"
        
        # è¾“å‡ºè·¯å¾„
        if output_path and output_path.endswith('.mp3'):
            mp3_path = output_path
        else:
            mp3_path = f"output/{timestamp}_tts.mp3"
        
        output_dir = Path(aiff_path).parent
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # ä½¿ç”¨ say å‘½ä»¤ç”ŸæˆéŸ³é¢‘ (ä½¿ç”¨ -v æŒ‡å®šè¯­éŸ³)
        cmd = ['say', '-v', voice, text, '-o', aiff_path]
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
        
        if result.returncode != 0:
            # å¤‡ç”¨ï¼šå°è¯•é»˜è®¤è¯­éŸ³
            cmd = ['say', text, '-o', aiff_path]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
        
        if result.returncode != 0:
            raise RuntimeError(f"TTS ç”Ÿæˆå¤±è´¥: {result.stderr}")
        
        # è½¬æ¢æ ¼å¼ä¸º MP3
        cmd = [
            'ffmpeg', '-y',
            '-i', aiff_path,
            '-acodec', 'libmp3lame',
            '-ar', '22050',
            mp3_path
        ]
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        # åˆ é™¤ aiff
        Path(aiff_path).unlink()
        
        if result.returncode == 0:
            return mp3_path
        
        raise RuntimeError(f"MP3 è½¬æ¢å¤±è´¥: {result.stderr}")


# ä¾¿æ·å‡½æ•°
async def quick_video(
    images: List[str],
    output_path: str = None,
    with_tts: str = None
) -> str:
    """å¿«é€Ÿç”Ÿæˆè§†é¢‘"""
    generator = VideoGenerator()
    
    # ç”Ÿæˆè§†é¢‘
    video_path = await generator.generate_from_images(images, output_path)
    
    # æ·»åŠ éŸ³é¢‘
    if with_tts:
        video_path = await generator.add_audio(video_path, tts_text=with_tts)
    
    return video_path


async def generate_from_content(content_id: str, base_dir: str = None) -> str:
    """
    ä»å†…å®¹IDç”Ÿæˆå®Œæ•´è§†é¢‘ï¼ˆå«TTSï¼‰
    
    Args:
        content_id: å†…å®¹IDï¼ˆå¦‚ 011ï¼‰
        base_dir: åŸºç¡€ç›®å½•
    
    Returns:
        str: ç”Ÿæˆçš„è§†é¢‘è·¯å¾„
    """
    from pathlib import Path
    
    if not base_dir:
        base_dir = Path(__file__).parent.parent
    else:
        base_dir = Path(base_dir)
    
    # æŸ¥æ‰¾å†…å®¹æ–‡ä»¶
    content_file = None
    for folder in ['input', 'processing']:
        folder_path = base_dir / folder
        for f in folder_path.glob(f"{content_id}_*.md"):
            content_file = f
            break
        if content_file:
            break
    
    if not content_file:
        raise FileNotFoundError(f"æœªæ‰¾åˆ°å†…å®¹: {content_id}")
    
    # è¯»å–å†…å®¹
    with open(content_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æå–æ ‡é¢˜å’Œæ­£æ–‡
    title = ""
    body = ""
    in_frontmatter = False
    for line in content.split('\n'):
        if line.strip() == '---':
            in_frontmatter = not in_frontmatter
        elif not in_frontmatter:
            if line.startswith('# '):
                title = line[2:].strip()
            elif line.strip():
                body += line + '\n'
    
    # æŸ¥æ‰¾å›¾ç‰‡
    images = []
    input_folder = base_dir / 'input'
    for ext in ['.jpg', '.jpeg', '.png']:
        for img in input_folder.glob(f"{content_id}*{ext}"):
            images.append(str(img))
    
    if not images:
        raise FileNotFoundError(f"æœªæ‰¾åˆ°å†…å®¹ {content_id} çš„å›¾ç‰‡")
    
    # ç”Ÿæˆè§†é¢‘
    gen = VideoGenerator()
    output_dir = base_dir / 'output'
    output_dir.mkdir(exist_ok=True)
    
    video_path = await gen.generate_from_images(
        images,
        str(output_dir / f"{content_id}_final_video.mp4"),
        duration_per_image=4.0
    )
    
    # ç”Ÿæˆ TTS
    tts_text = title + 'ã€‚' + body[:500]  # é™åˆ¶é•¿åº¦
    audio_path = await gen._generate_tts(tts_text)
    
    # åˆå¹¶
    final_path = await gen.add_audio(video_path, audio_path=audio_path)
    
    return final_path


async def generate_complete_video(
    content_id: str,
    base_dir: str = None,
    with_subtitles: bool = True,
    background_music: str = None
) -> str:
    """
    ç”Ÿæˆå®Œæ•´è§†é¢‘ï¼ˆå«å­—å¹•ã€èƒŒæ™¯éŸ³ä¹ï¼‰
    
    Args:
        content_id: å†…å®¹ID
        base_dir: åŸºç¡€ç›®å½•
        with_subtitles: æ˜¯å¦æ·»åŠ å­—å¹•
        background_music: èƒŒæ™¯éŸ³ä¹è·¯å¾„
    
    Returns:
        str: æœ€ç»ˆè§†é¢‘è·¯å¾„
    """
    from pathlib import Path
    
    if not base_dir:
        base_dir = Path(__file__).parent.parent
    else:
        base_dir = Path(base_dir)
    
    gen = VideoGenerator()
    output_dir = base_dir / 'output'
    
    # 1. ç”ŸæˆåŸºç¡€è§†é¢‘
    images = []
    input_folder = base_dir / 'input'
    for ext in ['.jpg', '.jpeg', '.png']:
        for img in input_folder.glob(f"{content_id}*{ext}"):
            images.append(str(img))
    
    if not images:
        raise FileNotFoundError(f"æœªæ‰¾åˆ°å›¾ç‰‡: {content_id}")
    
    video_path = await gen.generate_from_images(
        images,
        str(output_dir / f"{content_id}_step1_video.mp4"),
        duration_per_image=4.0
    )
    
    # 2. è¯»å–å†…å®¹ç”Ÿæˆ TTS
    content_file = None
    for folder in ['input', 'processing']:
        folder_path = base_dir / folder
        for f in folder_path.glob(f"{content_id}_*.md"):
            content_file = f
            break
        if content_file:
            break
    
    title = ""
    body = ""
    if content_file:
        with open(content_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        in_frontmatter = False
        for line in content.split('\n'):
            if line.strip() == '---':
                in_frontmatter = not in_frontmatter
            elif not in_frontmatter:
                if line.startswith('# '):
                    title = line[2:].strip()
                elif line.strip():
                    body += line + ' '
    
    # ç”Ÿæˆ TTS
    tts_text = f"{title}ã€‚{body[:300]}"
    audio_path = await gen._generate_tts(tts_text)
    
    # 3. æ·»åŠ  TTS éŸ³é¢‘
    video_path = await gen.add_audio(
        video_path,
        audio_path=audio_path,
        output_path=str(output_dir / f"{content_id}_step2_with_audio.mp4")
    )
    
    # 4. æ·»åŠ å­—å¹•ï¼ˆå¯é€‰ï¼‰
    if with_subtitles and tts_text:
        # ç®€å•æŒ‰æ—¶é—´å¹³å‡åˆ†é…å­—å¹•
        duration = 4.0 * len(images)
        num_subs = min(len(tts_text) // 20, 10)  # æ¯20å­—ä¸€ä¸ªå­—å¹•ï¼Œæœ€å¤š10ä¸ª
        if num_subs > 0:
            sub_duration = duration / num_subs
            subtitles = []
            words = tts_text[:200].split('ã€‚')  # ç®€å•åˆ†å¥
            for i, segment in enumerate(words[:num_subs]):
                if segment.strip():
                    subtitles.append({
                        "text": segment.strip() + "ã€‚",
                        "start": i * sub_duration,
                        "end": (i + 1) * sub_duration
                    })
            
            if subtitles:
                video_path = await gen.add_subtitles(
                    video_path,
                    subtitles,
                    str(output_dir / f"{content_id}_step3_with_subtitles.mp4")
                )
    
    # 5. æ·»åŠ èƒŒæ™¯éŸ³ä¹ï¼ˆå¯é€‰ï¼‰
    if background_music and Path(background_music).exists():
        video_path = await gen.add_background_music(
            video_path,
            background_music,
            str(output_dir / f"{content_id}_final_complete.mp4")
        )
    
    return video_path
    """
    ä»å†…å®¹IDç”Ÿæˆå®Œæ•´è§†é¢‘ï¼ˆå«TTSï¼‰
    
    Args:
        content_id: å†…å®¹IDï¼ˆå¦‚ 011ï¼‰
        base_dir: åŸºç¡€ç›®å½•
    
    Returns:
        str: ç”Ÿæˆçš„è§†é¢‘è·¯å¾„
    """
    from pathlib import Path
    
    if not base_dir:
        base_dir = Path(__file__).parent.parent
    else:
        base_dir = Path(base_dir)
    
    # æŸ¥æ‰¾å†…å®¹æ–‡ä»¶
    content_file = None
    for folder in ['input', 'processing']:
        folder_path = base_dir / folder
        for f in folder_path.glob(f"{content_id}_*.md"):
            content_file = f
            break
        if content_file:
            break
    
    if not content_file:
        raise FileNotFoundError(f"æœªæ‰¾åˆ°å†…å®¹: {content_id}")
    
    # è¯»å–å†…å®¹
    with open(content_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æå–æ ‡é¢˜å’Œæ­£æ–‡
    title = ""
    body = ""
    in_frontmatter = False
    for line in content.split('\n'):
        if line.strip() == '---':
            in_frontmatter = not in_frontmatter
        elif not in_frontmatter:
            if line.startswith('# '):
                title = line[2:].strip()
            elif line.strip():
                body += line + '\n'
    
    # æŸ¥æ‰¾å›¾ç‰‡
    images = []
    input_folder = base_dir / 'input'
    for ext in ['.jpg', '.jpeg', '.png']:
        for img in input_folder.glob(f"{content_id}*{ext}"):
            images.append(str(img))
    
    if not images:
        raise FileNotFoundError(f"æœªæ‰¾åˆ°å†…å®¹ {content_id} çš„å›¾ç‰‡")
    
    # ç”Ÿæˆè§†é¢‘
    gen = VideoGenerator()
    output_dir = base_dir / 'output'
    output_dir.mkdir(exist_ok=True)
    
    video_path = await gen.generate_from_images(
        images,
        str(output_dir / f"{content_id}_final_video.mp4"),
        duration_per_image=4.0
    )
    
    # ç”Ÿæˆ TTS
    tts_text = title + 'ã€‚' + body[:500]  # é™åˆ¶é•¿åº¦
    audio_path = await gen._generate_tts(tts_text)
    
    # åˆå¹¶
    final_path = await gen.add_audio(video_path, audio_path=audio_path)
    
    return final_path


if __name__ == "__main__":
    import sys
    
    gen = VideoGenerator()
    print("ğŸ¬ è§†é¢‘ç”Ÿæˆå™¨")
    print(f"é…ç½®çŠ¶æ€: {'âœ… å·²é…ç½®' if gen.is_configured() else 'âŒ æœªé…ç½®'}")
    
    if len(sys.argv) > 1:
        # æµ‹è¯•ç”Ÿæˆ
        images = sys.argv[1:]
        print(f"ä» {len(images)} å¼ å›¾ç‰‡ç”Ÿæˆè§†é¢‘...")
        
        async def test():
            path = await gen.generate_from_images(images)
            print(f"âœ… è§†é¢‘ç”ŸæˆæˆåŠŸ: {path}")
        
        asyncio.run(test())
