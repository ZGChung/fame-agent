#!/usr/bin/env python3
"""
è§†é¢‘ç”Ÿæˆæ¨¡å—
æ”¯æŒå¤šç§ AI è§†é¢‘ç”ŸæˆæœåŠ¡

ä½¿ç”¨æ–¹å¼:
1. é…ç½®è§†é¢‘ç”ŸæˆæœåŠ¡ API
2. è°ƒç”¨ generate_video() ç”Ÿæˆè§†é¢‘
3. é›†æˆåˆ° pipeline

æ”¯æŒçš„è§†é¢‘ç”Ÿæˆæ–¹å¼:
- Runway ML (text to video, image to video)
- Pika Labs (text to video, image to video)
- Luma Dream Machine (image to video)
- æœ¬åœ° ffmpeg (å›¾ç‰‡ç”Ÿæˆè§†é¢‘)
"""

import os
import json
import asyncio
import subprocess
from pathlib import Path
from typing import Optional, List
from datetime import datetime

# é…ç½®
CONFIG_FILE = Path(__file__).parent.parent / "config.json"

def load_config() -> dict:
    """åŠ è½½é…ç½®"""
    if CONFIG_FILE.exists():
        with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}


class VideoGenerator:
    """è§†é¢‘ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.config = load_config()
        self.video_config = self.config.get('video', {})
    
    def is_configured(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦é…ç½®äº†ä»»æ„è§†é¢‘æœåŠ¡"""
        return bool(
            self.video_config.get('runway_api_key') or
            self.video_config.get('pika_api_key') or
            self.video_config.get('luma_api_key') or
            self.video_config.get('heygen_api_key')
        )
    
    async def generate_from_images(
        self,
        images: List[str],
        output_path: str = None,
        duration_per_image: float = 3.0,
        transition: str = "fade"
    ) -> str:
        """
        ä»å›¾ç‰‡ç”Ÿæˆè§†é¢‘ï¼ˆå¹»ç¯ç‰‡ï¼‰
        
        Args:
            images: å›¾ç‰‡è·¯å¾„åˆ—è¡¨
            output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
            duration_per_image: æ¯å¼ å›¾ç‰‡æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
            transition: è½¬åœºæ•ˆæœ (fade, slide, none)
        
        Returns:
            str: ç”Ÿæˆè§†é¢‘çš„è·¯å¾„
        """
        if not images:
            raise ValueError("éœ€è¦æä¾›è‡³å°‘ä¸€å¼ å›¾ç‰‡")
        
        if not output_path:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = f"output/{timestamp}_video.mp4"
        
        # ä½¿ç”¨ ffmpeg ç”Ÿæˆè§†é¢‘
        success = await self._ffmpeg_slideshow(
            images, output_path, duration_per_image, transition
        )
        
        if success:
            return output_path
        raise RuntimeError("è§†é¢‘ç”Ÿæˆå¤±è´¥")
    
    async def _ffmpeg_slideshow(
        self,
        images: List[str],
        output_path: str,
        duration: float,
        transition: str
    ) -> bool:
        """ä½¿ç”¨ ffmpeg ç”Ÿæˆå¹»ç¯ç‰‡è§†é¢‘"""
        
        output_dir = Path(output_path).parent
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # å¦‚æœåªæœ‰ä¸€å¼ å›¾ç‰‡ï¼Œç›´æ¥å¤åˆ¶
        if len(images) == 1:
            cmd = [
                'ffmpeg', '-y',
                '-loop', '1',
                '-i', images[0],
                '-c:v', 'libx264',
                '-t', str(duration),
                '-pix_fmt', 'yuv420p',
                '-vf', f'scale=1080:1920:force_original_aspect_ratio=decrease,pad=1080:1920:(ow-iw)/2:(oh-ih)/2',
                output_path
            ]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
            return result.returncode == 0
        
        # å¤šå¼ å›¾ç‰‡ï¼šåˆ›å»ºç‰‡æ®µååˆå¹¶
        try:
            temp_videos = []
            for i, img in enumerate(images):
                temp_out = output_dir / f"temp_{i}.mp4"
                cmd = [
                    'ffmpeg', '-y',
                    '-loop', '1',
                    '-i', img,
                    '-c:v', 'libx264',
                    '-t', str(duration),
                    '-pix_fmt', 'yuv420p',
                    '-vf', f'scale=1080:1920:force_original_aspect_ratio=decrease,pad=1080:1920:(ow-iw)/2:(oh-ih)/2',
                    str(temp_out)
                ]
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
                if result.returncode != 0:
                    print(f"åˆ›å»ºç‰‡æ®µå¤±è´¥: {result.stderr[:200]}")
                    return False
                temp_videos.append(str(temp_out))
            
            # åˆå¹¶
            concat_file = output_dir / "concat.txt"
            with open(concat_file, 'w') as f:
                for v in temp_videos:
                    f.write(f"file '{v}'\n")
            
            cmd = [
                'ffmpeg', '-y',
                '-f', 'concat',
                '-safe', '0',
                '-i', str(concat_file),
                '-c', 'copy',
                output_path
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
            
            # æ¸…ç†
            for v in temp_videos:
                Path(v).unlink()
            concat_file.unlink()
            
            return result.returncode == 0
            
        except Exception as e:
            print(f"FFmpeg ç”Ÿæˆå¤±è´¥: {e}")
            return False
    
    async def generate_text_to_video(
        self,
        prompt: str,
        service: str = "runway",
        output_path: str = None
    ) -> str:
        """
        æ–‡å­—ç”Ÿæˆè§†é¢‘
        
        Args:
            prompt: è§†é¢‘æè¿°
            service: æœåŠ¡å•† (runway, pika, luma)
            output_path: è¾“å‡ºè·¯å¾„
        
        Returns:
            str: è§†é¢‘è·¯å¾„
        """
        if service == "runway":
            return await self._runway_generate(prompt, output_path)
        elif service == "pika":
            return await self._pika_generate(prompt, output_path)
        elif service == "luma":
            return await self._luma_generate(prompt, output_path)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æœåŠ¡: {service}")
    
    async def _runway_generate(self, prompt: str, output_path: str) -> str:
        """Runway ML API"""
        api_key = self.video_config.get('runway_api_key')
        if not api_key:
            raise ValueError("éœ€è¦é…ç½® Runway API Key")
        
        # TODO: å®ç° Runway API è°ƒç”¨
        # API: https://api.runwayml.com/v1/generation
        raise NotImplementedError("Runway API é›†æˆå¼€å‘ä¸­")
    
    async def _pika_generate(self, prompt: str, output_path: str) -> str:
        """Pika Labs API"""
        api_key = self.video_config.get('pika_api_key')
        if not api_key:
            raise ValueError("éœ€è¦é…ç½® Pika API Key")
        
        # TODO: å®ç° Pika API è°ƒç”¨
        raise NotImplementedError("Pika API é›†æˆå¼€å‘ä¸­")
    
    async def _luma_generate(self, prompt: str, output_path: str) -> str:
        """Luma Dream Machine API"""
        api_key = self.video_config.get('luma_api_key')
        if not api_key:
            raise ValueError("éœ€è¦é…ç½® Luma API Key")
        
        # TODO: å®ç° Luma API è°ƒç”¨
        raise NotImplementedError("Luma API é›†æˆå¼€å‘ä¸­")
    
    async def add_audio(
        self,
        video_path: str,
        audio_path: str = None,
        tts_text: str = None,
        output_path: str = None
    ) -> str:
        """
        ä¸ºè§†é¢‘æ·»åŠ éŸ³é¢‘
        
        Args:
            video_path: è§†é¢‘è·¯å¾„
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„ (å¯é€‰)
            tts_text: è¦è½¬è¯­éŸ³çš„æ–‡å­— (å¯é€‰)
            output_path: è¾“å‡ºè·¯å¾„
        
        Returns:
            str: å¸¦éŸ³é¢‘çš„è§†é¢‘è·¯å¾„
        """
        if not output_path:
            output_path = video_path.replace('.mp4', '_with_audio.mp4')
        
        # å¦‚æœæä¾›äº† ttsï¼Œä½¿ç”¨ TTS ç”ŸæˆéŸ³é¢‘
        if tts_text and not audio_path:
            audio_path = await self._generate_tts(tts_text)
            if not audio_path:
                raise ValueError("TTS ç”Ÿæˆå¤±è´¥")
        
        if not audio_path:
            raise ValueError("éœ€è¦æä¾›éŸ³é¢‘æ–‡ä»¶æˆ– TTS æ–‡å­—")
        
        # åˆå¹¶è§†é¢‘å’ŒéŸ³é¢‘
        cmd = [
            'ffmpeg', '-y',
            '-i', video_path,
            '-i', audio_path,
            '-c:v', 'copy',
            '-c:a', 'aac',
            '-shortest',
            output_path
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode == 0:
            return output_path
        raise RuntimeError(f"éŸ³é¢‘åˆå¹¶å¤±è´¥: {result.stderr}")
    
    async def _generate_tts(self, text: str, output_path: str = None) -> str:
        """ç”Ÿæˆ TTS éŸ³é¢‘ (ä½¿ç”¨ macOS say å‘½ä»¤)"""
        # å…ˆç”Ÿæˆ aiff
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        aiff_path = f"output/{timestamp}_tts.aiff"
        
        # è¾“å‡ºè·¯å¾„
        if output_path and output_path.endswith('.mp3'):
            mp3_path = output_path
        else:
            mp3_path = f"output/{timestamp}_tts.mp3"
        
        output_dir = Path(aiff_path).parent
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # ä½¿ç”¨ say å‘½ä»¤ç”ŸæˆéŸ³é¢‘
        text_file = output_dir / "tts_text.txt"
        with open(text_file, 'w') as f:
            f.write(text)
        
        cmd = ['say', '-f', str(text_file), '-o', aiff_path]
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        text_file.unlink()
        
        if result.returncode != 0:
            raise RuntimeError(f"TTS ç”Ÿæˆå¤±è´¥: {result.stderr}")
        
        # è½¬æ¢æ ¼å¼ä¸º MP3
        cmd = [
            'ffmpeg', '-y',
            '-i', aiff_path,
            '-acodec', 'libmp3lame',
            '-ar', '22050',
            mp3_path
        ]
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        # åˆ é™¤ aiff
        Path(aiff_path).unlink()
        
        if result.returncode == 0:
            return mp3_path
        
        raise RuntimeError(f"MP3 è½¬æ¢å¤±è´¥: {result.stderr}")


# ä¾¿æ·å‡½æ•°
async def quick_video(
    images: List[str],
    output_path: str = None,
    with_tts: str = None
) -> str:
    """å¿«é€Ÿç”Ÿæˆè§†é¢‘"""
    generator = VideoGenerator()
    
    # ç”Ÿæˆè§†é¢‘
    video_path = await generator.generate_from_images(images, output_path)
    
    # æ·»åŠ éŸ³é¢‘
    if with_tts:
        video_path = await generator.add_audio(video_path, tts_text=with_tts)
    
    return video_path


if __name__ == "__main__":
    import sys
    
    gen = VideoGenerator()
    print("ğŸ¬ è§†é¢‘ç”Ÿæˆå™¨")
    print(f"é…ç½®çŠ¶æ€: {'âœ… å·²é…ç½®' if gen.is_configured() else 'âŒ æœªé…ç½®'}")
    
    if len(sys.argv) > 1:
        # æµ‹è¯•ç”Ÿæˆ
        images = sys.argv[1:]
        print(f"ä» {len(images)} å¼ å›¾ç‰‡ç”Ÿæˆè§†é¢‘...")
        
        async def test():
            path = await gen.generate_from_images(images)
            print(f"âœ… è§†é¢‘ç”ŸæˆæˆåŠŸ: {path}")
        
        asyncio.run(test())
